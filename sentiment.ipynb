{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection in Twitter Data\n",
    "The scope of this notebook is to implement a Naive-Bayes classifier that can be used to predict emotion in Twitter messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the location of the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "dataDir = \"ssec-aggregated/\"\n",
    "trainFile = dataDir+\"train-combined-0.0.csv\"\n",
    "testFile = dataDir+\"test-combined-0.0.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define function to parse our training and testing sets.\n",
    "\n",
    "**tokenizePhrase** takes a text message, removes @ mentions and # hashtags  as well as non-alphabetic characters and stop-words and returns the remaining words.\n",
    "\n",
    "**parseSentence** Takes a line from the training or testing file,  separates and parses the sentiment fields and the message field and returns an array of boolean sentiment flags as well as a tokenised version of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KnownSentiments = [\"Anger\", \"Anticipation\", \"Disgust\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\", \"Trust\"]\n",
    "dropAts=False\n",
    "dropHashtags=False\n",
    "\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def tokenizePhrase(phrase):\n",
    "    # Drop @-references used in social media texts.\n",
    "    if dropAts:\n",
    "        phrase = re.sub(\"@[^ ]*\", \"\", phrase)\n",
    "        \n",
    "    # Drop hashtags\n",
    "    if dropHashtags:\n",
    "        phrase = re.sub(\"#[^ ]*\", \"\", phrase)\n",
    "        \n",
    "    # Change non-alphabetic characters to spaces\n",
    "    phrase = re.sub(\"[^A-Za-z]\", \" \", phrase).lower()\n",
    "    \n",
    "    # Tokenize phrase while removing stop words and dropping tokens that are not more than 1 char long.\n",
    "    tokens = [w for w in word_tokenize(phrase) if w not in eng_stopwords and len(w)>1]\n",
    "    \n",
    "    return tokens\n",
    "    \n",
    "def parseSentence(sent):\n",
    "    # The sentiment labels are encoded at the beginning of the line as tab-separated fields\n",
    "    # Split the line by tabs so as to extract the labels and the text\n",
    "    parts = sent.split(\"\\t\")\n",
    "    \n",
    "    if len(parts)<9:\n",
    "        return ([], [])\n",
    "    \n",
    "    sentSents = parts[:8]\n",
    "    \n",
    "    # Match the sentiment labels with the known sentiments to extract a boolean vector \n",
    "    # encoding which sentiments are present.\n",
    "    sentMap = [sentSents[i]==KnownSentiments[i] for i in range(0, len(sentSents))]\n",
    "\n",
    "    \n",
    "    # The actual text\n",
    "    phrase = parts[8]\n",
    "    \n",
    "    tokens = tokenizePhrase(phrase)\n",
    "    \n",
    "    #return the sentiment map and the tokens extracted from the phrase\n",
    "    return (sentMap, tokens)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **BoW** class implements Bag of Words. \n",
    "\n",
    "The **fit** method takes a collection of tokens and adds them to the Bag of Words.\n",
    "\n",
    "The **transform** method takes a collection of tokens and returns a term-document vector correspondnding to the tokens\n",
    "\n",
    "The **fit_transform** method combines the other fit and transform methods into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "class BoW:\n",
    "\n",
    "    def fit(self, phraseTokens):\n",
    "        for tok in phraseTokens:\n",
    "            if tok not in self.vocabulary_:\n",
    "                tok_ndx = len(self.vocabulary_)\n",
    "                self.vocabulary_[tok]=tok_ndx\n",
    "                self.index_[tok_ndx]=tok\n",
    "                 \n",
    "    def transform(self, phraseTokens):\n",
    "        return [i for i in [self.vocabulary_.get(t, None) for t in phraseTokens] if i is not None]\n",
    "    \n",
    "    def fit_transform(self, phraseTokens):\n",
    "        self.fit(phraseTokens)\n",
    "        return self.transform(phraseTokens)\n",
    "    \n",
    "    vocabulary_=dict()\n",
    "    index_=dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class **NaiveBayes1** is an implementation of the Naive Bayes multinomial classifier algorithm. \n",
    "\n",
    "Apart from label-wise prediction, NaiveBayes1 also maintains pairwise probabilities of labels, so for every pair of labels (X,Y), the class keeps track of P(X|Y), P(¬X|Y), P(X|¬Y) and P(¬X|¬Y). It also has the capability of accepting a set of pairwise dependencies to alter the final prediction probabilities. We can use this capability to skew the prediction probabilities towards a label **x** given an independent label-wise prediction **y**. For example, we can use this to model the probability of anger|fear, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# p(y|x) = p(x|y).p(y)\n",
    "class NaiveBayes1:\n",
    "    def __init__(self, classes):\n",
    "\n",
    "        self.classes_=list(classes)\n",
    "        print \"Initialising NaiveBayes1 class with \", len(self.classes_), \" classes...\"\n",
    "        self.globalCounts = np.zeros(1000) # pre-allocate 1000 tokens\n",
    "        self.labelWordCounts = np.zeros((len(classes), 1000)) \n",
    "        self.pairwiseCountsMatched = np.zeros((len(classes), len(classes), 1000))\n",
    "        self.pairwiseCountsMismatched = np.zeros((len(classes), len(classes), 1000))\n",
    "        \n",
    "    def update(self, labels, tokens):\n",
    "        for w in tokens:\n",
    "            toAdd=0\n",
    "            # Does the word exist in our vocab?\n",
    "            if w >= len(self.globalCounts):\n",
    "                # No - extend the counts array to accomodate\n",
    "                toAdd = int(math.ceil((w-len(self.globalCounts)+1) / 1000.0) * 1000)\n",
    "                self.globalCounts = np.append(self.globalCounts, np.zeros(toAdd))\n",
    "\n",
    "                \n",
    "            self.globalCounts[w] += 1\n",
    "\n",
    "            if toAdd>0:\n",
    "                self.labelWordCounts = np.append(self.labelWordCounts, np.zeros((len(self.classes_),toAdd)), axis=1)\n",
    "                self.pairwiseCountsMatched = np.append(self.pairwiseCountsMatched, np.zeros((len(self.classes_), len(self.classes_), toAdd)), axis=2) \n",
    "                self.pairwiseCountsMismatched = np.append(self.pairwiseCountsMismatched, np.zeros((len(self.classes_), len(self.classes_), toAdd)), axis=2)  \n",
    "\n",
    "            for x in range(0, len(self.classes_)):\n",
    "\n",
    "                if labels[x]:\n",
    "                    self.labelWordCounts[x, w] += 1\n",
    "                \n",
    "                for y in range(0, len(self.classes_)):\n",
    "                    if (y>x): # avoid count split in two elements\n",
    "                        if labels[x]:\n",
    "                            if labels[y]:\n",
    "                                self.pairwiseCountsMatched[x,y, w]+=1 # x:y\n",
    "                            else:\n",
    "                                self.pairwiseCountsMismatched[x,y,w]+=1 # x:¬y\n",
    "                    else:\n",
    "                        if not labels[x]: \n",
    "                            if not labels[y]:\n",
    "                                self.pairwiseCountsMatched[x, y, w]+=1 # ¬x:¬y\n",
    "                            else:\n",
    "                                self.pairwiseCountsMismatched[x, y, w]+=1 # ¬x:y\n",
    "                            \n",
    "        #self.recalc()\n",
    "        \n",
    "        \n",
    "    def recalc(self):\n",
    "        classProbs = np.array(self.labelWordCounts)\n",
    "\n",
    "        # Laplace smoothed word probability by emotion - p(w|e) \n",
    "        # classes x tokens\n",
    "        self.wordClassPosProbs = (1.0 * classProbs+1)/(sum(classProbs)+len(classProbs)) # p(x|y)\n",
    "\n",
    "        # emotion probability - p(e) - element per class\n",
    "        self.posClassProbs = np.sum(classProbs, axis=1)\n",
    "        self.posClassProbs = (1.0*self.posClassProbs)/sum(self.posClassProbs) # p(y)\n",
    "        \n",
    "        classProbs = np.array(self.globalCounts) - classProbs\n",
    "        \n",
    "        # Laplace smoothed word probability by negative emotion - p(w|¬e)\n",
    "        self.wordClassNegProbs = (1.0 * classProbs+1)/(sum(classProbs)+len(classProbs))\n",
    "\n",
    "        # negative emotion probability - p(¬e) - element per class\n",
    "        self.negClassProbs = np.sum(classProbs, axis=1)\n",
    "        self.negClassProbs = (1.0*self.negClassProbs)/sum(self.negClassProbs) # p(¬y)\n",
    "        \n",
    "        # pairwise emotion conditional probability - p(e1 | e2) - class x class\n",
    "        tempCounts = np.sum(self.pairwiseCountsMatched, axis=2)\n",
    "        self.pairwiseClassProbs_x_y_matched = np.zeros((len(self.classes_), len(self.classes_)))\n",
    "        for x in range(0, len(self.classes_)):\n",
    "            for y in range(0, len(self.classes_)):\n",
    "                if x==y:\n",
    "                    self.pairwiseClassProbs_x_y_matched[x, y]=1\n",
    "                else:\n",
    "                    if y > x: # p(x|y)\n",
    "                        self.pairwiseClassProbs_x_y_matched[x, y] = (1.0*tempCounts[x, y])/(sum(self.labelWordCounts[x]))\n",
    "                        self.pairwiseClassProbs_x_y_matched[y, x] = (1.0*tempCounts[y, x])/(sum(self.globalCounts)-sum(self.labelWordCounts[x]))\n",
    "                        \n",
    "        # p(¬e1|e1), p(e1|¬e2)                \n",
    "        tempCounts = np.sum(self.pairwiseCountsMismatched, axis=2)\n",
    "        self.pairwiseClassProbs_x_y_mismatched = np.zeros((len(self.classes_), len(self.classes_)))\n",
    "        for x in range(0, len(self.classes_)):\n",
    "            for y in range(0, len(self.classes_)):\n",
    "                if x==y:\n",
    "                    self.pairwiseClassProbs_x_y_mismatched[x, y]=0\n",
    "                else:\n",
    "                    if y > x:  \n",
    "                        self.pairwiseClassProbs_x_y_mismatched[x, y] = (1.0*tempCounts[x, y])/(sum(self.labelWordCounts[x])) # p(x|¬y)\n",
    "                        self.pairwiseClassProbs_x_y_mismatched[y, x] = (1.0*tempCounts[y, x])/(sum(self.globalCounts)-sum(self.labelWordCounts[x])) # p(¬x|y)\n",
    "\n",
    "        # pairwise emotion conditional probability - p(e2 | e1) - class x class\n",
    "        tempCounts = np.sum(self.pairwiseCountsMatched, axis=2)\n",
    "        self.pairwiseClassProbs_y_x_matched = np.zeros((len(self.classes_), len(self.classes_)))\n",
    "        for x in range(0, len(self.classes_)):\n",
    "            for y in range(0, len(self.classes_)):\n",
    "                if x==y:\n",
    "                    self.pairwiseClassProbs_y_x_matched[x, y]=1\n",
    "                else:\n",
    "                    if y > x: # p(y|x)\n",
    "                        self.pairwiseClassProbs_y_x_matched[x, y] = (1.0*tempCounts[x, y])/(sum(self.labelWordCounts[y]))\n",
    "                        self.pairwiseClassProbs_y_x_matched[y, x] = (1.0*tempCounts[y, x])/(sum(self.globalCounts)-sum(self.labelWordCounts[y])) #p(¬y|¬x)\n",
    "\n",
    "        # p(¬e2|e1), p(e2|¬e1)                \n",
    "        tempCounts = np.sum(self.pairwiseCountsMismatched, axis=2)\n",
    "        self.pairwiseClassProbs_y_x_mismatched = np.zeros((len(self.classes_), len(self.classes_)))\n",
    "        for x in range(0, len(self.classes_)):\n",
    "            for y in range(0, len(self.classes_)):\n",
    "                if x==y:\n",
    "                    self.pairwiseClassProbs_y_x_mismatched[x, y]=0\n",
    "                else:\n",
    "                    if y > x: # p(y|¬x)\n",
    "                        self.pairwiseClassProbs_y_x_mismatched[x, y] = (1.0*tempCounts[x, y])/(sum(self.labelWordCounts[y]))\n",
    "                        self.pairwiseClassProbs_y_x_mismatched[y, x] = (1.0*tempCounts[y, x])/(sum(self.globalCounts)-sum(self.labelWordCounts[y])) #\\p(¬y|x)\n",
    "                        \n",
    "    # set pairs of classes to correlate in results\n",
    "    # { 1: 2 } -> add p(c1|c2) to prediction\n",
    "    # { -1: 2 } -> add p(¬c1|c2) to prediction\n",
    "    # { 1: -2 } -> add p(c1|¬c2) to prediction\n",
    "    \n",
    "    def setPariwiseDependencies(self, classPairs):\n",
    "        self.classPairs = classPairs\n",
    "        \n",
    "    def classify(self, tokens):\n",
    "        classPredictions = [False] * len(self.classes_)\n",
    "        \n",
    "        posClassProbs=[1.0]*len(classPredictions)\n",
    "        negClassProbs=[1.0]*len(classPredictions)\n",
    "        \n",
    "        for tok in tokens:\n",
    "            if tok < len(self.globalCounts):\n",
    "                posClassProbs *= self.wordClassPosProbs[:, tok]\n",
    "            \n",
    "                negClassProbs *= self.wordClassNegProbs[:, tok]\n",
    "                \n",
    "        posClassProbs *= self.posClassProbs\n",
    "        negClassProbs *= self.negClassProbs\n",
    "        \n",
    "        preds = posClassProbs>negClassProbs\n",
    "\n",
    "        for key, values in self.classPairs.iteritems():\n",
    "            notKey = key<0\n",
    "            for value in values:\n",
    "                notValue = value<0\n",
    "                #print key, value\n",
    "                if abs(value) > abs(key):\n",
    "                    if key > 0:\n",
    "                        if (notValue and not preds[abs(value)-1]) or (not notValue and preds[abs(value)-1]):\n",
    "                            if notValue:\n",
    "                                #print \"#b\", key, value\n",
    "                                posClassProbs[key-1] *= self.pairwiseClassProbs_x_y_mismatched[key-1, (-value)-1]\n",
    "                            else:\n",
    "                                #print \"#a\", key, value\n",
    "                                posClassProbs[key-1] *= self.pairwiseClassProbs_x_y_matched[key-1, value-1]\n",
    "\n",
    "                    else:\n",
    "                        if (notValue and not preds[abs(value)-1]) or (not notValue and preds[abs(value)-1]):\n",
    "                            if notValue:\n",
    "                                #print \"#d\", key, value\n",
    "                                negClassProbs[(-key)-1] *= self.pairwiseClassProbs_x_y_matched[(-value)-1, (-key)-1]\n",
    "                            else:\n",
    "                                #print \"#c\", key, value\n",
    "                                negClassProbs[(-key)-1] *= self.pairwiseClassProbs_x_y_mismatched[value-1, (-key)-1]\n",
    "                else:\n",
    "                    if key > 0:\n",
    "                        if (notValue and not preds[abs(value)-1]) or (not notValue and preds[abs(value)-1]):\n",
    "                            if notValue:\n",
    "                                posClassProbs[key-1] *= self.pairwiseClassProbs_y_x_mismatched[(-value)-1, key-1]\n",
    "                            else:\n",
    "                                posClassProbs[key-1] *= self.pairwiseClassProbs_y_x_matched[value-1, key-1]\n",
    "                    else:\n",
    "                        if (notValue and not preds[abs(value)-1]) or (not notValue and preds[abs(value)-1]):\n",
    "                            if notValue:\n",
    "                                negClassProbs[(-key)-1] *= self.pairwiseClassProbs_y_x_matched[ (-key)-1, (-value)-1]\n",
    "                            else:\n",
    "                                negClassProbs[(-key)-1] *= self.pairwiseClassProbs_y_x_mismatched[(-key)-1, value-1]\n",
    "                        \n",
    "                                            \n",
    "        preds = posClassProbs>negClassProbs\n",
    "        \n",
    "        return preds\n",
    "                    \n",
    "        \n",
    "    classes_=list()\n",
    "    globalCounts=np.array([]) # array of counts indexed by token id\n",
    "    labelWordCounts=np.array([]) # array of classes_ rows x tokens columns\n",
    "    # array classes x classes x tokens\n",
    "    # for y>x (top diagonal half) contains counts where sentiment(x) and sentiment(y)\n",
    "    # for x<y (bottom diagonal half) contains counts where not(sentiment(x)) and not(sentiment(y))\n",
    "    pairwiseCountsMatched=np.array([]) \n",
    "    \n",
    "    # array classes x classes x tokens\n",
    "    # for y>x (top diagonal half) contains counts where sentiment(x) and not(sentiment(y))\n",
    "    # for x<y (bottom diagonal half) contains counts where not(sentiment(x)) and sentiment(y)\n",
    "    pairwiseCountsMismatched=np.array([]) \n",
    "    classPairs=dict() # dict of emotion id -> emotion id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelScores:\n",
    "    def __init__(self, knownClasses):\n",
    "        self.knownClasses = knownClasses\n",
    "        self.truePositives = np.zeros(len(knownClasses))\n",
    "        self.trueNegatives = np.zeros(len(knownClasses))\n",
    "        self.falsePositives = np.zeros(len(knownClasses))\n",
    "        self.falseNegatives = np.zeros(len(knownClasses))\n",
    "        \n",
    "    def accumulate(self, predictedLabels, trainingLabels):\n",
    "        self.truePositives += np.logical_and(predictedLabels, trainingLabels)\n",
    "        self.trueNegatives += np.logical_and(np.logical_not(predictedLabels), np.logical_not(trainingLabels))\n",
    "        self.falsePositives += np.logical_and(preds, np.logical_not(trainingLabels))\n",
    "        self.falseNegatives += np.logical_and(np.logical_not(preds), trainingLabels)\n",
    "\n",
    "    def getStats(self):\n",
    "        precision = self.truePositives / (self.truePositives+self.falsePositives)\n",
    "        recall = self.truePositives / (self.truePositives+self.falseNegatives)\n",
    "        accuracy = (self.truePositives+self.trueNegatives)/(self.truePositives+self.trueNegatives+self.falsePositives+self.falseNegatives)\n",
    "        \n",
    "        f1 = 2* ((precision * recall)/(precision + recall))\n",
    "        \n",
    "        return (accuracy, precision, recall, f1)\n",
    "    \n",
    "    def printScores(self):\n",
    "        (accuracy, precision, recall, f1score) = self.getStats()\n",
    "        print self.knownClasses\n",
    "        print \"true positives = \", self.truePositives\n",
    "        print \"true negatives = \", self.trueNegatives\n",
    "        print \"false positives = \", self.falsePositives\n",
    "        print \"false negatives = \", self.falseNegatives\n",
    "        print\n",
    "        print \"accuracy=\", np.round(accuracy, 3)\n",
    "        print \"precision=\", np.round(precision, 3)\n",
    "        print \"recall=\", np.round(recall, 3)\n",
    "        print \"f1score=\", np.round(f1score, 3)\n",
    "        \n",
    "    def getDeltas(self, other):\n",
    "        (o_accuracy, o_precision, o_recall, o_f1) = other.getStats()\n",
    "        (accuracy, precision, recall, f1) = self.getStats()\n",
    "        \n",
    "        return (accuracy-o_accuracy, precision-o_precision, recall-o_recall, f1-o_f1)\n",
    "    \n",
    "    def printDeltas(self, other):\n",
    "        (accuracy, precision, recall, f1) = self.getDeltas(other)\n",
    "        \n",
    "        print \"delta accuracy=\", np.round(accuracy, 3)\n",
    "        print \"delta precision=\", np.round(precision, 3)\n",
    "        print \"delta recall=\", np.round(recall, 3)\n",
    "        print \"delta f1score=\", np.round(f1, 3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Individual Emotions\n",
    "\n",
    "Predict individual emotions based on the training data. \n",
    "\n",
    "No dependencies between different emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising NaiveBayes1 class with  8  classes...\n"
     ]
    }
   ],
   "source": [
    "bow = BoW() # Create empty Bag of Words\n",
    "nb1 = NaiveBayes1(KnownSentiments) # Create Naive Bayes class with the known sentiments as labels.\n",
    "i=0\n",
    "# Process the training file line-by-line\n",
    "for line in open(trainFile):\n",
    "    #print i, line\n",
    "    (classMap, tokens)=parseSentence(line) # Parse each sentence returning sentiments and tokens\n",
    "    token_ndx = bow.fit_transform(tokens) # Transform tokens to term-document frequency\n",
    "    \n",
    "    nb1.update(classMap, token_ndx) # Update the Naive Bayes class with the new training data\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "nb1.recalc() # Recalculate the probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510. 1050.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.   49. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 846.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247.  11. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.562 0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.554   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.99  0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.71    nan 0.379]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "nb1.setPariwiseDependencies({}) # Assume NO pairwise dependencies between labels\n",
    "origScores = ModelScores(KnownSentiments)\n",
    "\n",
    "# Process the test file\n",
    "for line in open(testFile):\n",
    "    # Parse, tokenise and BoW...\n",
    "    (testClassMap, tokens) = parseSentence(line)\n",
    "    if (tokens is None):\n",
    "        continue\n",
    "    tokens = bow.transform(tokens)\n",
    "    # ... and use Naive Bayes to classify\n",
    "    preds = nb1.classify(tokens)\n",
    "     \n",
    "    origScores.accumulate(preds, testClassMap)\n",
    "\n",
    "origScores.printScores()\n",
    "(orig_accuracy, orig_precision, orig_recall, orig_f1) = origScores.getStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that the model seems never to be predicting \"surprise\", hence it leads to undefined precision and f1-score values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Manual addition of relationships between emotion labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Pariwise combinations of 2 emotion labels.\n",
    "\n",
    "We select Anger and Sadness and try all pairwise combinations of the two to determine the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness|Anger\n",
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510. 1044.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.   61. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 834.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247.  17. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.565 0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.556   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.984 0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.71    nan 0.379]\n",
      "delta accuracy= [0.    0.    0.    0.    0.    0.003 0.    0.   ]\n",
      "delta precision= [0.    0.    0.    0.    0.    0.002   nan 0.   ]\n",
      "delta recall= [ 0.     0.     0.     0.     0.    -0.006  0.     0.   ]\n",
      "delta f1score= [ 0.  0.  0.  0.  0.  0. nan  0.]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬Sadness|Anger\n",
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510. 1057.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.   18. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 877.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247.   4. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.55  0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.547   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.996 0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.706   nan 0.379]\n",
      "delta accuracy= [ 0.     0.     0.     0.     0.    -0.012  0.     0.   ]\n",
      "delta precision= [ 0.     0.     0.     0.     0.    -0.007    nan  0.   ]\n",
      "delta recall= [0.    0.    0.    0.    0.    0.007 0.    0.   ]\n",
      "delta f1score= [ 0.     0.     0.     0.     0.    -0.004    nan  0.   ]\n",
      "\n",
      "Sadness|¬Anger\n",
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510. 1047.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.   62. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 833.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247.  14. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.567 0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.557   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.987 0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.712   nan 0.379]\n",
      "delta accuracy= [0.    0.    0.    0.    0.    0.005 0.    0.   ]\n",
      "delta precision= [0.    0.    0.    0.    0.    0.003   nan 0.   ]\n",
      "delta recall= [ 0.     0.     0.     0.     0.    -0.003  0.     0.   ]\n",
      "delta f1score= [0.    0.    0.    0.    0.    0.002   nan 0.   ]\n",
      "\n",
      "¬Sadness|¬Anger\n",
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510. 1052.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.   45. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 850.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247.   9. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.561 0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.553   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.992 0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.71    nan 0.379]\n",
      "delta accuracy= [ 0.     0.     0.     0.     0.    -0.001  0.     0.   ]\n",
      "delta precision= [ 0.     0.     0.     0.     0.    -0.001    nan  0.   ]\n",
      "delta recall= [0.    0.    0.    0.    0.    0.002 0.    0.   ]\n",
      "delta f1score= [ 0.  0.  0.  0.  0. -0. nan  0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Anger | Sadness\n",
    "for label2 in [1, -1]:\n",
    "    for label1 in [6, -6]:\n",
    "        \n",
    "        nb1.setPariwiseDependencies({label1:[label2]})\n",
    "        scores = ModelScores(KnownSentiments)\n",
    "\n",
    "        for line in open(testFile):\n",
    "            (testClassMap, tokens) = parseSentence(line)\n",
    "            if (tokens is None):\n",
    "                continue\n",
    "            tokens = bow.transform(tokens)\n",
    "            preds = nb1.classify(tokens)\n",
    "\n",
    "            scores.accumulate(preds, testClassMap)\n",
    "                    \n",
    "        if label1 < 0:\n",
    "            NotChar1=\"¬\"\n",
    "        else:\n",
    "            NotChar1=\"\"\n",
    "            \n",
    "        if label2 < 0:\n",
    "            NotChar2=\"¬\"\n",
    "        else:\n",
    "            NotChar2=\"\"\n",
    "            \n",
    "        print NotChar1+KnownSentiments[abs(label1)-1]+\"|\"+NotChar2+KnownSentiments[abs(label2)-1]\n",
    "        scores.printScores()\n",
    "        \n",
    "        scores.printDeltas(origScores)\n",
    "        \n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Adding multiple relationships between labels manually (extra part - not in assignment)\n",
    "Here we plot a heat map of pairwise class probability in order to see promising correlations between emotions. We use these heat maps to decide which relations to use to improve prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAOECAYAAABKBtchAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c503ec790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "f, ([ax1, ax3], [ax2, ax4]) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "plt.subplots_adjust(bottom=-0.25)\n",
    "\n",
    "sentLabels = [\" \"]\n",
    "sentLabels.extend(KnownSentiments)\n",
    "\n",
    "ax1.imshow(nb1.pairwiseClassProbs_x_y_matched, cmap='hot', interpolation='nearest')\n",
    "ax1.set_title(\"p(x|y) {top right}, p(x', y') {bottom left}\")\n",
    "ax1.set_yticklabels(sentLabels)\n",
    "ax1.set_xticklabels(sentLabels, rotation=\"45\")\n",
    "\n",
    "ax3.imshow(nb1.pairwiseClassProbs_x_y_mismatched, cmap='hot', interpolation='nearest')\n",
    "ax3.set_title(\"p(x|y') {top right}, p(x', y) {bottom left}\")\n",
    "ax3.set_yticklabels(sentLabels)\n",
    "ax3.set_yticklabels(sentLabels)\n",
    "ax3.set_xticklabels(sentLabels, rotation=\"45\")\n",
    "\n",
    "ax2.imshow(nb1.pairwiseClassProbs_y_x_matched, cmap='hot', interpolation='nearest')\n",
    "ax2.set_title(\"p(y|x) {top right}, p(y', x') {bottom left}\")\n",
    "ax2.set_yticklabels(sentLabels)\n",
    "ax2.set_yticklabels(sentLabels)\n",
    "ax2.set_xticklabels(sentLabels, rotation=\"45\")\n",
    "\n",
    "ax4.imshow(nb1.pairwiseClassProbs_y_x_mismatched, cmap='hot', interpolation='nearest')\n",
    "ax4.set_title(\"p(y|x') {top right}, p(y', x) {bottom left}\")\n",
    "ax4.set_yticklabels(sentLabels)\n",
    "ax4.set_yticklabels(sentLabels)\n",
    "ax4.set_xticklabels(sentLabels, rotation=\"45\")\n",
    "\n",
    "plt.show()\n",
    "#print nb1.pairwiseClassProbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to improve our prediction of \"Sadness\" whose accuracy is only slightly higher than 50%. According to the heat map, p(Sadness|fear), p(Sadness|disgust) and p(sadness|anger) are all quite high, therefore if we incorporate these correlations in our model, we should get a better prediction for \"Sadness\". \n",
    "\n",
    "It turns out, however that p(sadness|¬fear), p(sadness|¬disgust) and p(sadness|¬anger) are highly negatively correlated and these in the model gives a better prediction for sadness. Including both sets of correlations at the same time however is counterproductive. We manage to improve sadness accuract to 0.614 (up 5.2%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1239. 1129.  664.  145.  510.  824.    0.  175.]\n",
      "true negatives =  [  62.   89.  570. 1081.  724.  377. 1429. 1207.]\n",
      "false positives =  [649. 662. 474.  75. 475. 518.   0.  68.]\n",
      "false negatives =  [  6.  76. 248. 655. 247. 237. 527. 506.]\n",
      "\n",
      "accuracy= [0.665 0.623 0.631 0.627 0.631 0.614 0.731 0.707]\n",
      "precision= [0.656 0.63  0.583 0.659 0.518 0.614   nan 0.72 ]\n",
      "recall= [0.995 0.937 0.728 0.181 0.674 0.777 0.    0.257]\n",
      "f1score= [0.791 0.754 0.648 0.284 0.586 0.686   nan 0.379]\n",
      "delta accuracy= [0.    0.    0.    0.    0.    0.052 0.    0.   ]\n",
      "delta precision= [0.   0.   0.   0.   0.   0.06  nan 0.  ]\n",
      "delta recall= [ 0.     0.     0.     0.     0.    -0.213  0.     0.   ]\n",
      "delta f1score= [ 0.     0.     0.     0.     0.    -0.024    nan  0.   ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#nb1.setPariwiseDependencies({6:[1,-7,-8], -8:[6], -7:[6]})\n",
    "#nb1.setPariwiseDependencies({6:[1, 3, 4], -6:[7,8], 1:[6]})\n",
    "nb1.setPariwiseDependencies({6:[-1,-3,-4], -6:[-5, 7, 8]})\n",
    "#nb1.setPariwiseDependencies({})\n",
    "\n",
    "scores = ModelScores(KnownSentiments)\n",
    "\n",
    "for line in open(testFile):\n",
    "    (testClassMap, tokens) = parseSentence(line)\n",
    "    if (tokens is None):\n",
    "        continue\n",
    "    tokens = bow.transform(tokens)\n",
    "    preds = nb1.classify(tokens)\n",
    "     \n",
    "    scores.accumulate(preds, testClassMap)\n",
    "\n",
    "scores.printScores()\n",
    "scores.printDeltas(origScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Best set of pairwise variable assignments\n",
    "We now want to search through all pairwise combinations of emotions and all four combinations of conditional probability assignments (x|y, x|¬y, ¬x|y, ¬x|¬y) to find the best assignments. We perform a grid search over all the possible combinations and keep a record of those that improve prediction accuracy of x. Avoid taking x|y and x|¬y simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n",
      "Evaluating P( Anger | Anticipation )\n",
      "{1: [2]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6763803680981595 ( 0.011247443762781195 )\n",
      "Evaluating P( Anger | Disgust )\n",
      "{1: [3]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6641104294478528 ( -0.0010224948875254825 )\n",
      "Evaluating P( Anger | Fear )\n",
      "{1: [4]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6656441717791411 ( 0.0005112474437628522 )\n",
      "Evaluating P( Anger | Joy )\n",
      "{1: [5]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.679959100204499 ( 0.014826175869120717 )\n",
      "Evaluating P( Anger | Sadness )\n",
      "{1: [6]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6676891615541922 ( 0.002556237218813928 )\n",
      "Evaluating P( Anger | Surprise )\n",
      "{1: [7]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( Anger | Trust )\n",
      "{1: [8]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6809815950920245 ( 0.0158486707566462 )\n",
      "Evaluating P( Anger | !Anticipation )\n",
      "{1: [-2]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( Anger | !Disgust )\n",
      "{1: [-3]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6825153374233128 ( 0.017382413087934534 )\n",
      "Evaluating P( Anger | !Fear )\n",
      "{1: [-4]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6722903885480572 ( 0.007157464212678932 )\n",
      "Evaluating P( Anger | !Joy )\n",
      "{1: [-5]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( Anger | !Sadness )\n",
      "{1: [-6]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6697341513292433 ( 0.004601226993865004 )\n",
      "Evaluating P( Anger | !Surprise )\n",
      "{1: [-7]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6671779141104295 ( 0.002044989775051187 )\n",
      "Evaluating P( Anger | !Trust )\n",
      "{1: [-8]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6641104294478528 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Anger | Anticipation )\n",
      "{-1: [2]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.661042944785276 ( -0.004089979550102263 )\n",
      "Evaluating P( !Anger | Disgust )\n",
      "{-1: [3]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( !Anger | Fear )\n",
      "{-1: [4]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6646216768916156 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Anger | Joy )\n",
      "{-1: [5]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( !Anger | Sadness )\n",
      "{-1: [6]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6549079754601227 ( -0.010224948875255602 )\n",
      "Evaluating P( !Anger | Surprise )\n",
      "{-1: [7]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( !Anger | Trust )\n",
      "{-1: [8]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( !Anger | !Anticipation )\n",
      "{-1: [-2]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6651329243353783 ( 0.0 )\n",
      "Evaluating P( !Anger | !Disgust )\n",
      "{-1: [-3]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6620654396728016 ( -0.0030674846625766694 )\n",
      "Evaluating P( !Anger | !Fear )\n",
      "{-1: [-4]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.661042944785276 ( -0.004089979550102263 )\n",
      "Evaluating P( !Anger | !Joy )\n",
      "{-1: [-5]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6646216768916156 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Anger | !Sadness )\n",
      "{-1: [-6]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6641104294478528 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Anger | !Surprise )\n",
      "{-1: [-7]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6620654396728016 ( -0.0030674846625766694 )\n",
      "Evaluating P( !Anger | !Trust )\n",
      "{-1: [-8]}\n",
      "    Edge changed accuracy from  0.6651329243353783  to  0.6620654396728016 ( -0.0030674846625766694 )\n",
      "Beneficial edges for  Anger :\n",
      "P( Anger | Anticipation ), delta= 0.011247443762781195\n",
      "P( Anger | !Disgust ), delta= 0.017382413087934534\n",
      "P( Anger | !Fear ), delta= 0.007157464212678932\n",
      "(4, 8)\n",
      "Evaluating P( Anticipation | Anger )\n",
      "{2: [1]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6273006134969326 ( 0.004601226993865115 )\n",
      "Evaluating P( Anticipation | Disgust )\n",
      "{2: [3]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.626278118609407 ( 0.0035787321063395217 )\n",
      "Evaluating P( Anticipation | Fear )\n",
      "{2: [4]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6206543967280164 ( -0.002044989775051076 )\n",
      "Evaluating P( Anticipation | Joy )\n",
      "{2: [5]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6257668711656442 ( 0.0030674846625767804 )\n",
      "Evaluating P( Anticipation | Sadness )\n",
      "{2: [6]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6257668711656442 ( 0.0030674846625767804 )\n",
      "Evaluating P( Anticipation | Surprise )\n",
      "{2: [7]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6226993865030674 ( 0.0 )\n",
      "Evaluating P( Anticipation | Trust )\n",
      "{2: [8]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6242331288343558 ( 0.0015337423312883347 )\n",
      "Evaluating P( Anticipation | !Anger )\n",
      "{2: [-1]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.621676891615542 ( -0.0010224948875254825 )\n",
      "Evaluating P( Anticipation | !Disgust )\n",
      "{2: [-3]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6232106339468303 ( 0.0005112474437628522 )\n",
      "Evaluating P( Anticipation | !Fear )\n",
      "{2: [-4]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6252556237218814 ( 0.002556237218813928 )\n",
      "Evaluating P( Anticipation | !Joy )\n",
      "{2: [-5]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6221881390593047 ( -0.0005112474437627412 )\n",
      "Evaluating P( Anticipation | !Sadness )\n",
      "{2: [-6]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6226993865030674 ( 0.0 )\n",
      "Evaluating P( Anticipation | !Surprise )\n",
      "{2: [-7]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6232106339468303 ( 0.0005112474437628522 )\n",
      "Evaluating P( Anticipation | !Trust )\n",
      "{2: [-8]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6252556237218814 ( 0.002556237218813928 )\n",
      "Evaluating P( !Anticipation | Anger )\n",
      "{-2: [1]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6232106339468303 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Anticipation | Disgust )\n",
      "{-2: [3]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.621676891615542 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Anticipation | Fear )\n",
      "{-2: [4]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6226993865030674 ( 0.0 )\n",
      "Evaluating P( !Anticipation | Joy )\n",
      "{-2: [5]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6252556237218814 ( 0.002556237218813928 )\n",
      "Evaluating P( !Anticipation | Sadness )\n",
      "{-2: [6]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6196319018404908 ( -0.0030674846625766694 )\n",
      "Evaluating P( !Anticipation | Surprise )\n",
      "{-2: [7]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6226993865030674 ( 0.0 )\n",
      "Evaluating P( !Anticipation | Trust )\n",
      "{-2: [8]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6242331288343558 ( 0.0015337423312883347 )\n",
      "Evaluating P( !Anticipation | !Anger )\n",
      "{-2: [-1]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6226993865030674 ( 0.0 )\n",
      "Evaluating P( !Anticipation | !Disgust )\n",
      "{-2: [-3]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6257668711656442 ( 0.0030674846625767804 )\n",
      "Evaluating P( !Anticipation | !Fear )\n",
      "{-2: [-4]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.621676891615542 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Anticipation | !Joy )\n",
      "{-2: [-5]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6186094069529653 ( -0.004089979550102152 )\n",
      "Evaluating P( !Anticipation | !Sadness )\n",
      "{-2: [-6]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6232106339468303 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Anticipation | !Surprise )\n",
      "{-2: [-7]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.6247443762781186 ( 0.002044989775051187 )\n",
      "Evaluating P( !Anticipation | !Trust )\n",
      "{-2: [-8]}\n",
      "    Edge changed accuracy from  0.6226993865030674  to  0.621676891615542 ( -0.0010224948875254825 )\n",
      "Beneficial edges for  Anticipation :\n",
      "P( Anticipation | Anger ), delta= 0.004601226993865115\n",
      "P( !Anticipation | Anger ), delta= 0.0005112474437628522\n",
      "P( Anticipation | Disgust ), delta= 0.0035787321063395217\n",
      "P( !Anticipation | !Disgust ), delta= 0.0030674846625767804\n",
      "P( Anticipation | !Fear ), delta= 0.002556237218813928\n",
      "(4, 8)\n",
      "Evaluating P( Disgust | Anger )\n",
      "{3: [1]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edge changed accuracy from  0.630879345603272  to  0.6334355828220859 ( 0.002556237218813928 )\n",
      "Evaluating P( Disgust | Anticipation )\n",
      "{3: [2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6400817995910021 ( 0.00920245398773012 )\n",
      "Evaluating P( Disgust | Fear )\n",
      "{3: [4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.635480572597137 ( 0.004601226993865004 )\n",
      "Evaluating P( Disgust | Joy )\n",
      "{3: [5]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6395705521472392 ( 0.008691206543967267 )\n",
      "Evaluating P( Disgust | Sadness )\n",
      "{3: [6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6405930470347648 ( 0.00971370143149286 )\n",
      "Evaluating P( Disgust | Surprise )\n",
      "{3: [7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Disgust | Trust )\n",
      "{3: [8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6344580777096115 ( 0.0035787321063395217 )\n",
      "Evaluating P( Disgust | !Anger )\n",
      "{3: [-1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Disgust | !Anticipation )\n",
      "{3: [-2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6313905930470347 ( 0.0005112474437627412 )\n",
      "Evaluating P( Disgust | !Fear )\n",
      "{3: [-4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6436605316973415 ( 0.01278118609406953 )\n",
      "Evaluating P( Disgust | !Joy )\n",
      "{3: [-5]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6319018404907976 ( 0.0010224948875255935 )\n",
      "Evaluating P( Disgust | !Sadness )\n",
      "{3: [-6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Disgust | !Surprise )\n",
      "{3: [-7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6375255623721882 ( 0.006646216768916191 )\n",
      "Evaluating P( Disgust | !Trust )\n",
      "{3: [-8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6313905930470347 ( 0.0005112474437627412 )\n",
      "Evaluating P( !Disgust | Anger )\n",
      "{-3: [1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5766871165644172 ( -0.05419222903885479 )\n",
      "Evaluating P( !Disgust | Anticipation )\n",
      "{-3: [2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5950920245398773 ( -0.03578732106339466 )\n",
      "Evaluating P( !Disgust | Fear )\n",
      "{-3: [4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6232106339468303 ( -0.0076687116564416735 )\n",
      "Evaluating P( !Disgust | Joy )\n",
      "{-3: [5]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6114519427402862 ( -0.01942740286298572 )\n",
      "Evaluating P( !Disgust | Sadness )\n",
      "{-3: [6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5633946830265849 ( -0.06748466257668706 )\n",
      "Evaluating P( !Disgust | Surprise )\n",
      "{-3: [7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( !Disgust | Trust )\n",
      "{-3: [8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.626278118609407 ( -0.004601226993865004 )\n",
      "Evaluating P( !Disgust | !Anger )\n",
      "{-3: [-1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6303680981595092 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Disgust | !Anticipation )\n",
      "{-3: [-2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6313905930470347 ( 0.0005112474437627412 )\n",
      "Evaluating P( !Disgust | !Fear )\n",
      "{-3: [-4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6068507157464212 ( -0.024028629856850725 )\n",
      "Evaluating P( !Disgust | !Joy )\n",
      "{-3: [-5]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6155419222903885 ( -0.015337423312883458 )\n",
      "Evaluating P( !Disgust | !Sadness )\n",
      "{-3: [-6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6293456032719836 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Disgust | !Surprise )\n",
      "{-3: [-7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6124744376278118 ( -0.018404907975460127 )\n",
      "Evaluating P( !Disgust | !Trust )\n",
      "{-3: [-8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.598159509202454 ( -0.03271983640081799 )\n",
      "Beneficial edges for  Disgust :\n",
      "P( Disgust | Anger ), delta= 0.002556237218813928\n",
      "P( Disgust | Anticipation ), delta= 0.00920245398773012\n",
      "P( !Disgust | !Anticipation ), delta= 0.0005112474437627412\n",
      "P( Disgust | !Fear ), delta= 0.01278118609406953\n",
      "(4, 8)\n",
      "Evaluating P( Fear | Anger )\n",
      "{4: [1]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6252556237218814 ( -0.0015337423312883347 )\n",
      "Evaluating P( Fear | Anticipation )\n",
      "{4: [2]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6170756646216768 ( -0.00971370143149286 )\n",
      "Evaluating P( Fear | Disgust )\n",
      "{4: [3]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6180981595092024 ( -0.008691206543967267 )\n",
      "Evaluating P( Fear | Joy )\n",
      "{4: [5]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6226993865030674 ( -0.004089979550102263 )\n",
      "Evaluating P( Fear | Sadness )\n",
      "{4: [6]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.623721881390593 ( -0.0030674846625766694 )\n",
      "Evaluating P( Fear | Surprise )\n",
      "{4: [7]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6267893660531697 ( 0.0 )\n",
      "Evaluating P( Fear | Trust )\n",
      "{4: [8]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6288343558282209 ( 0.002044989775051187 )\n",
      "Evaluating P( Fear | !Anger )\n",
      "{4: [-1]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6273006134969326 ( 0.0005112474437628522 )\n",
      "Evaluating P( Fear | !Anticipation )\n",
      "{4: [-2]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6267893660531697 ( 0.0 )\n",
      "Evaluating P( Fear | !Disgust )\n",
      "{4: [-3]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6278118609406953 ( 0.0010224948875255935 )\n",
      "Evaluating P( Fear | !Joy )\n",
      "{4: [-5]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.628323108384458 ( 0.0015337423312883347 )\n",
      "Evaluating P( Fear | !Sadness )\n",
      "{4: [-6]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6278118609406953 ( 0.0010224948875255935 )\n",
      "Evaluating P( Fear | !Surprise )\n",
      "{4: [-7]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6247443762781186 ( -0.002044989775051076 )\n",
      "Evaluating P( Fear | !Trust )\n",
      "{4: [-8]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6257668711656442 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Fear | Anger )\n",
      "{-4: [1]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6273006134969326 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Fear | Anticipation )\n",
      "{-4: [2]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6252556237218814 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Fear | Disgust )\n",
      "{-4: [3]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6206543967280164 ( -0.006134969325153339 )\n",
      "Evaluating P( !Fear | Joy )\n",
      "{-4: [5]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6226993865030674 ( -0.004089979550102263 )\n",
      "Evaluating P( !Fear | Sadness )\n",
      "{-4: [6]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.5853783231083844 ( -0.04141104294478526 )\n",
      "Evaluating P( !Fear | Surprise )\n",
      "{-4: [7]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6267893660531697 ( 0.0 )\n",
      "Evaluating P( !Fear | Trust )\n",
      "{-4: [8]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6226993865030674 ( -0.004089979550102263 )\n",
      "Evaluating P( !Fear | !Anger )\n",
      "{-4: [-1]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6252556237218814 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Fear | !Anticipation )\n",
      "{-4: [-2]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6252556237218814 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Fear | !Disgust )\n",
      "{-4: [-3]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6257668711656442 ( -0.0010224948875254825 )\n",
      "Evaluating P( !Fear | !Joy )\n",
      "{-4: [-5]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6273006134969326 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Fear | !Sadness )\n",
      "{-4: [-6]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6267893660531697 ( 0.0 )\n",
      "Evaluating P( !Fear | !Surprise )\n",
      "{-4: [-7]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6273006134969326 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Fear | !Trust )\n",
      "{-4: [-8]}\n",
      "    Edge changed accuracy from  0.6267893660531697  to  0.6324130879345603 ( 0.005623721881390598 )\n",
      "Beneficial edges for  Fear :\n",
      "P( Fear | !Anger ), delta= 0.0005112474437628522\n",
      "P( !Fear | Anger ), delta= 0.0005112474437628522\n",
      "P( Fear | !Disgust ), delta= 0.0010224948875255935\n",
      "(4, 8)\n",
      "Evaluating P( Joy | Anger )\n",
      "{5: [1]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edge changed accuracy from  0.630879345603272  to  0.6702453987730062 ( 0.03936605316973418 )\n",
      "Evaluating P( Joy | Anticipation )\n",
      "{5: [2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6497955010224948 ( 0.01891615541922287 )\n",
      "Evaluating P( Joy | Disgust )\n",
      "{5: [3]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6579754601226994 ( 0.027096114519427394 )\n",
      "Evaluating P( Joy | Fear )\n",
      "{5: [4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6400817995910021 ( 0.00920245398773012 )\n",
      "Evaluating P( Joy | Sadness )\n",
      "{5: [6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6712678936605317 ( 0.04038854805725978 )\n",
      "Evaluating P( Joy | Surprise )\n",
      "{5: [7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Joy | Trust )\n",
      "{5: [8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Joy | !Anger )\n",
      "{5: [-1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( Joy | !Anticipation )\n",
      "{5: [-2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6344580777096115 ( 0.0035787321063395217 )\n",
      "Evaluating P( Joy | !Disgust )\n",
      "{5: [-3]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6359918200408998 ( 0.005112474437627856 )\n",
      "Evaluating P( Joy | !Fear )\n",
      "{5: [-4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6533742331288344 ( 0.02249488752556239 )\n",
      "Evaluating P( Joy | !Sadness )\n",
      "{5: [-6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6313905930470347 ( 0.0005112474437627412 )\n",
      "Evaluating P( Joy | !Surprise )\n",
      "{5: [-7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6487730061349694 ( 0.017893660531697386 )\n",
      "Evaluating P( Joy | !Trust )\n",
      "{5: [-8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6625766871165644 ( 0.0316973415132924 )\n",
      "Evaluating P( !Joy | Anger )\n",
      "{-5: [1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6129856850715747 ( -0.017893660531697275 )\n",
      "Evaluating P( !Joy | Anticipation )\n",
      "{-5: [2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5894683026584867 ( -0.04141104294478526 )\n",
      "Evaluating P( !Joy | Disgust )\n",
      "{-5: [3]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6012269938650306 ( -0.029652351738241323 )\n",
      "Evaluating P( !Joy | Fear )\n",
      "{-5: [4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6293456032719836 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Joy | Sadness )\n",
      "{-5: [6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5869120654396728 ( -0.04396728016359919 )\n",
      "Evaluating P( !Joy | Surprise )\n",
      "{-5: [7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.630879345603272 ( 0.0 )\n",
      "Evaluating P( !Joy | Trust )\n",
      "{-5: [8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6339468302658486 ( 0.0030674846625766694 )\n",
      "Evaluating P( !Joy | !Anger )\n",
      "{-5: [-1]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6303680981595092 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Joy | !Anticipation )\n",
      "{-5: [-2]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6242331288343558 ( -0.006646216768916191 )\n",
      "Evaluating P( !Joy | !Disgust )\n",
      "{-5: [-3]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6226993865030674 ( -0.008179959100204526 )\n",
      "Evaluating P( !Joy | !Fear )\n",
      "{-5: [-4]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.5874233128834356 ( -0.043456032719836335 )\n",
      "Evaluating P( !Joy | !Sadness )\n",
      "{-5: [-6]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6303680981595092 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Joy | !Surprise )\n",
      "{-5: [-7]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6129856850715747 ( -0.017893660531697275 )\n",
      "Evaluating P( !Joy | !Trust )\n",
      "{-5: [-8]}\n",
      "    Edge changed accuracy from  0.630879345603272  to  0.6129856850715747 ( -0.017893660531697275 )\n",
      "Beneficial edges for  Joy :\n",
      "P( Joy | Anger ), delta= 0.03936605316973418\n",
      "P( Joy | Anticipation ), delta= 0.01891615541922287\n",
      "P( Joy | Disgust ), delta= 0.027096114519427394\n",
      "P( Joy | !Fear ), delta= 0.02249488752556239\n",
      "(4, 8)\n",
      "Evaluating P( Sadness | Anger )\n",
      "{6: [1]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5649284253578732 ( 0.0030674846625766694 )\n",
      "Evaluating P( Sadness | Anticipation )\n",
      "{6: [2]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5736196319018405 ( 0.011758691206543936 )\n",
      "Evaluating P( Sadness | Disgust )\n",
      "{6: [3]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5593047034764826 ( -0.002556237218813928 )\n",
      "Evaluating P( Sadness | Fear )\n",
      "{6: [4]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5613496932515337 ( -0.0005112474437628522 )\n",
      "Evaluating P( Sadness | Joy )\n",
      "{6: [5]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5853783231083844 ( 0.023517382413087873 )\n",
      "Evaluating P( Sadness | Surprise )\n",
      "{6: [7]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5618609406952966 ( 0.0 )\n",
      "Evaluating P( Sadness | Trust )\n",
      "{6: [8]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5777096114519428 ( 0.0158486707566462 )\n",
      "Evaluating P( Sadness | !Anger )\n",
      "{6: [-1]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5669734151329243 ( 0.005112474437627745 )\n",
      "Evaluating P( Sadness | !Anticipation )\n",
      "{6: [-2]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5613496932515337 ( -0.0005112474437628522 )\n",
      "Evaluating P( Sadness | !Disgust )\n",
      "{6: [-3]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5950920245398773 ( 0.03323108384458073 )\n",
      "Evaluating P( Sadness | !Fear )\n",
      "{6: [-4]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.6053169734151329 ( 0.043456032719836335 )\n",
      "Evaluating P( Sadness | !Joy )\n",
      "{6: [-5]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5623721881390593 ( 0.0005112474437627412 )\n",
      "Evaluating P( Sadness | !Surprise )\n",
      "{6: [-7]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5649284253578732 ( 0.0030674846625766694 )\n",
      "Evaluating P( Sadness | !Trust )\n",
      "{6: [-8]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5639059304703476 ( 0.002044989775051076 )\n",
      "Evaluating P( !Sadness | Anger )\n",
      "{-6: [1]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5495910020449898 ( -0.012269938650306789 )\n",
      "Evaluating P( !Sadness | Anticipation )\n",
      "{-6: [2]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5547034764826176 ( -0.007157464212678932 )\n",
      "Evaluating P( !Sadness | Disgust )\n",
      "{-6: [3]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5623721881390593 ( 0.0005112474437627412 )\n",
      "Evaluating P( !Sadness | Fear )\n",
      "{-6: [4]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.560838445807771 ( -0.0010224948875255935 )\n",
      "Evaluating P( !Sadness | Joy )\n",
      "{-6: [5]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.556237218813906 ( -0.005623721881390598 )\n",
      "Evaluating P( !Sadness | Surprise )\n",
      "{-6: [7]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5618609406952966 ( 0.0 )\n",
      "Evaluating P( !Sadness | Trust )\n",
      "{-6: [8]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5618609406952966 ( 0.0 )\n",
      "Evaluating P( !Sadness | !Anger )\n",
      "{-6: [-1]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.560838445807771 ( -0.0010224948875255935 )\n",
      "Evaluating P( !Sadness | !Anticipation )\n",
      "{-6: [-2]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5618609406952966 ( 0.0 )\n",
      "Evaluating P( !Sadness | !Disgust )\n",
      "{-6: [-3]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5567484662576687 ( -0.005112474437627856 )\n",
      "Evaluating P( !Sadness | !Fear )\n",
      "{-6: [-4]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5593047034764826 ( -0.002556237218813928 )\n",
      "Evaluating P( !Sadness | !Joy )\n",
      "{-6: [-5]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5603271983640081 ( -0.0015337423312884457 )\n",
      "Evaluating P( !Sadness | !Surprise )\n",
      "{-6: [-7]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5577709611451943 ( -0.004089979550102263 )\n",
      "Evaluating P( !Sadness | !Trust )\n",
      "{-6: [-8]}\n",
      "    Edge changed accuracy from  0.5618609406952966  to  0.5567484662576687 ( -0.005112474437627856 )\n",
      "Beneficial edges for  Sadness :\n",
      "P( Sadness | !Anger ), delta= 0.005112474437627745\n",
      "P( Sadness | Anticipation ), delta= 0.011758691206543936\n",
      "P( Sadness | !Disgust ), delta= 0.03323108384458073\n",
      "P( !Sadness | Disgust ), delta= 0.0005112474437627412\n",
      "P( Sadness | !Fear ), delta= 0.043456032719836335\n",
      "(4, 8)\n",
      "Evaluating P( Surprise | Anger )\n",
      "{7: [1]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Anticipation )\n",
      "{7: [2]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Disgust )\n",
      "{7: [3]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Fear )\n",
      "{7: [4]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Joy )\n",
      "{7: [5]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Sadness )\n",
      "{7: [6]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | Trust )\n",
      "{7: [8]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | !Anger )\n",
      "{7: [-1]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | !Anticipation )\n",
      "{7: [-2]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( Surprise | !Disgust )\n",
      "{7: [-3]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( Surprise | !Fear )\n",
      "{7: [-4]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( Surprise | !Joy )\n",
      "{7: [-5]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | !Sadness )\n",
      "{7: [-6]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( Surprise | !Trust )\n",
      "{7: [-8]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | Anger )\n",
      "{-7: [1]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | Anticipation )\n",
      "{-7: [2]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | Disgust )\n",
      "{-7: [3]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | Fear )\n",
      "{-7: [4]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | Joy )\n",
      "{-7: [5]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | Sadness )\n",
      "{-7: [6]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | Trust )\n",
      "{-7: [8]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | !Anger )\n",
      "{-7: [-1]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | !Anticipation )\n",
      "{-7: [-2]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | !Disgust )\n",
      "{-7: [-3]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | !Fear )\n",
      "{-7: [-4]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Surprise | !Joy )\n",
      "{-7: [-5]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | !Sadness )\n",
      "{-7: [-6]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7305725971370143 ( 0.0 )\n",
      "Evaluating P( !Surprise | !Trust )\n",
      "{-7: [-8]}\n",
      "    Edge changed accuracy from  0.7305725971370143  to  0.7300613496932515 ( -0.0005112474437627412 )\n",
      "Beneficial edges for  Surprise :\n",
      "(4, 8)\n",
      "Evaluating P( Trust | Anger )\n",
      "{8: [1]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.700920245398773 ( -0.005623721881390598 )\n",
      "Evaluating P( Trust | Anticipation )\n",
      "{8: [2]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7070552147239264 ( 0.0005112474437628522 )\n",
      "Evaluating P( Trust | Disgust )\n",
      "{8: [3]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7106339468302658 ( 0.004089979550102263 )\n",
      "Evaluating P( Trust | Fear )\n",
      "{8: [4]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7034764826175869 ( -0.0030674846625766694 )\n",
      "Evaluating P( Trust | Joy )\n",
      "{8: [5]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7075664621676891 ( 0.0010224948875255935 )\n",
      "Evaluating P( Trust | Sadness )\n",
      "{8: [6]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7004089979550102 ( -0.006134969325153339 )\n",
      "Evaluating P( Trust | Surprise )\n",
      "{8: [7]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7065439672801636 ( 0.0 )\n",
      "Evaluating P( Trust | !Anger )\n",
      "{8: [-1]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7060327198364008 ( -0.0005112474437627412 )\n",
      "Evaluating P( Trust | !Anticipation )\n",
      "{8: [-2]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7080777096114519 ( 0.0015337423312883347 )\n",
      "Evaluating P( Trust | !Disgust )\n",
      "{8: [-3]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7070552147239264 ( 0.0005112474437628522 )\n",
      "Evaluating P( Trust | !Fear )\n",
      "{8: [-4]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7070552147239264 ( 0.0005112474437628522 )\n",
      "Evaluating P( Trust | !Joy )\n",
      "{8: [-5]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7080777096114519 ( 0.0015337423312883347 )\n",
      "Evaluating P( Trust | !Sadness )\n",
      "{8: [-6]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7060327198364008 ( -0.0005112474437627412 )\n",
      "Evaluating P( Trust | !Surprise )\n",
      "{8: [-7]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7039877300613497 ( -0.002556237218813817 )\n",
      "Evaluating P( !Trust | Anger )\n",
      "{-8: [1]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7039877300613497 ( -0.002556237218813817 )\n",
      "Evaluating P( !Trust | Anticipation )\n",
      "{-8: [2]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.6947852760736196 ( -0.011758691206543936 )\n",
      "Evaluating P( !Trust | Disgust )\n",
      "{-8: [3]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7060327198364008 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Trust | Fear )\n",
      "{-8: [4]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7044989775051125 ( -0.002044989775051076 )\n",
      "Evaluating P( !Trust | Joy )\n",
      "{-8: [5]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.6993865030674846 ( -0.007157464212678932 )\n",
      "Evaluating P( !Trust | Sadness )\n",
      "{-8: [6]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7039877300613497 ( -0.002556237218813817 )\n",
      "Evaluating P( !Trust | Surprise )\n",
      "{-8: [7]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7065439672801636 ( 0.0 )\n",
      "Evaluating P( !Trust | !Anger )\n",
      "{-8: [-1]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7050102249488752 ( -0.0015337423312883347 )\n",
      "Evaluating P( !Trust | !Anticipation )\n",
      "{-8: [-2]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7065439672801636 ( 0.0 )\n",
      "Evaluating P( !Trust | !Disgust )\n",
      "{-8: [-3]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.6973415132924335 ( -0.009202453987730008 )\n",
      "Evaluating P( !Trust | !Fear )\n",
      "{-8: [-4]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.6988752556237219 ( -0.0076687116564416735 )\n",
      "Evaluating P( !Trust | !Joy )\n",
      "{-8: [-5]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7070552147239264 ( 0.0005112474437628522 )\n",
      "Evaluating P( !Trust | !Sadness )\n",
      "{-8: [-6]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7060327198364008 ( -0.0005112474437627412 )\n",
      "Evaluating P( !Trust | !Surprise )\n",
      "{-8: [-7]}\n",
      "    Edge changed accuracy from  0.7065439672801636  to  0.7029652351738241 ( -0.0035787321063394106 )\n",
      "Beneficial edges for  Trust :\n",
      "P( Trust | !Anticipation ), delta= 0.0015337423312883347\n",
      "P( Trust | Disgust ), delta= 0.004089979550102263\n",
      "P( Trust | !Fear ), delta= 0.0005112474437628522\n"
     ]
    }
   ],
   "source": [
    "globalPariwiseDependencies=dict()\n",
    "(origAccuracy, origPrecision, origRecall, origf1) = origScores.getStats()\n",
    "\n",
    "for x in range(0, len(KnownSentiments)):\n",
    "    deltas = np.zeros((4, len(KnownSentiments))) # x|y, x|y', x'|y, x'|y'\n",
    "    print deltas.shape\n",
    "    \n",
    "    for combination in range(0, 4):\n",
    "        for y in range(0, len(KnownSentiments)):\n",
    "            #print x, y\n",
    "            if x!=y:\n",
    "                sentx = KnownSentiments[x]\n",
    "                senty = KnownSentiments[y]\n",
    "                \n",
    "                x1=x+1\n",
    "                y1=y+1\n",
    "\n",
    "                    \n",
    "                if combination & 1:\n",
    "                    y1=-y1\n",
    "                    senty=\"!\"+senty\n",
    "                    \n",
    "                if combination & 2:\n",
    "                    x1=-x1\n",
    "                    sentx=\"!\"+sentx\n",
    "                \n",
    "                \n",
    "                print \"Evaluating P(\", sentx, \"|\", senty, \")\"\n",
    "                   \n",
    "                print({x1:[y1]})\n",
    "                nb1.setPariwiseDependencies({x1:[y1]})\n",
    "\n",
    "                scores = ModelScores(KnownSentiments)\n",
    "\n",
    "                for line in open(testFile):\n",
    "                    (testClassMap, tokens) = parseSentence(line)\n",
    "                    if (tokens is None):\n",
    "                        continue\n",
    "                    tokens = bow.transform(tokens)\n",
    "                    preds = nb1.classify(tokens)\n",
    "\n",
    "                    scores.accumulate(preds, testClassMap)\n",
    "                    \n",
    "                (a, p, r, f1) = scores.getStats()\n",
    "                (d_a, d_p, d_r, d_f1) = scores.getDeltas(origScores)\n",
    "            \n",
    "                #deltas[combination, y] = acc[x]-origAccuracy[x]\n",
    "                deltas[combination, y] = d_a[x]\n",
    "                print \"    Edge changed accuracy from \", origAccuracy[x], \" to \", a[x], \"(\" , deltas[combination, y], \")\"\n",
    "            \n",
    "    \n",
    "\n",
    "    print \"Beneficial edges for \", KnownSentiments[x], \":\"\n",
    "    for y in range(0, len(deltas)):\n",
    "        for combination in range(0, 4, 2):\n",
    "            if x!=y:\n",
    "                # Avoid adding both x|y and x|¬y - Choose the best option instead\n",
    "                if (deltas[combination, y]>0) or (deltas[combination+1, y]>0): \n",
    "                    if deltas[combination, y] > deltas[combination+1, y]:\n",
    "                        bestCombination = combination\n",
    "                    else:\n",
    "                        bestCombination = combination+1\n",
    "                        \n",
    "                    x1=x+1\n",
    "                    y1=y+1\n",
    "                    sentx = KnownSentiments[x]\n",
    "                    senty = KnownSentiments[y]\n",
    "\n",
    "                    if bestCombination & 1:\n",
    "                        y1=-y1\n",
    "                        senty=\"!\"+senty\n",
    "\n",
    "                    if bestCombination & 2:\n",
    "                        x1=-x1\n",
    "                        sentx=\"!\"+sentx\n",
    "\n",
    "                    print \"P(\", sentx, \"|\", senty, \"), delta=\", deltas[bestCombination, y]\n",
    "                    if x1 in globalPariwiseDependencies:\n",
    "                        globalPariwiseDependencies[x1].append(y1)\n",
    "                    else:\n",
    "                        globalPariwiseDependencies[x1]=[y1]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now re-classify the test set using the discovers relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2, -3, -4], 2: [1, 3, -4], 3: [1, 2, -4], 4: [-1, -3], 5: [1, 2, 3, -4], 6: [-1, 2, -3, -4], 8: [-2, 3, -4], -6: [3], -4: [1], -3: [-2]}\n",
      "['Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust']\n",
      "true positives =  [1152.  876.  411.  208.  243.  780.    0.  159.]\n",
      "true negatives =  [ 240.  333.  834. 1022. 1076.  402. 1429. 1228.]\n",
      "false positives =  [471. 418. 210. 134. 123. 493.   0.  47.]\n",
      "false negatives =  [ 93. 329. 501. 592. 514. 281. 527. 522.]\n",
      "\n",
      "accuracy= [0.712 0.618 0.637 0.629 0.674 0.604 0.731 0.709]\n",
      "precision= [0.71  0.677 0.662 0.608 0.664 0.613   nan 0.772]\n",
      "recall= [0.925 0.727 0.451 0.26  0.321 0.735 0.    0.233]\n",
      "f1score= [0.803 0.701 0.536 0.364 0.433 0.668   nan 0.359]\n",
      "delta accuracy= [ 0.047 -0.005  0.006  0.002  0.043  0.042  0.     0.003]\n",
      "delta precision= [ 0.054  0.047  0.078 -0.051  0.146  0.059    nan  0.052]\n",
      "delta recall= [-0.07  -0.21  -0.277  0.079 -0.353 -0.254  0.    -0.023]\n",
      "delta f1score= [ 0.012 -0.053 -0.112  0.08  -0.153 -0.042    nan -0.02 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etienne/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "print globalPariwiseDependencies\n",
    "\n",
    "nb1.setPariwiseDependencies(globalPariwiseDependencies)\n",
    "\n",
    "scores = ModelScores(KnownSentiments)\n",
    "\n",
    "for line in open(testFile):\n",
    "    (testClassMap, tokens) = parseSentence(line)\n",
    "    if (tokens is None):\n",
    "        continue\n",
    "    tokens = bow.transform(tokens)\n",
    "    preds = nb1.classify(tokens)\n",
    "     \n",
    "    scores.accumulate(preds, testClassMap)\n",
    "\n",
    "scores.printScores()\n",
    "\n",
    "scores.printDeltas(origScores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from the above results it appears that we managed to increase the scores in all classes except anticipation which dropped .5% in accuracy. Clearly this strategy, while, on the whole, increasing the predictive performance of th model is not optimal. A perfect method would be to go through th entire search space of the problem, but for pairwise matching of emotions that would mean (8x8x4)! possible configurations, but this is not tractable.\n",
    "\n",
    "A possible better method to search through this state space would possibly be a genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
